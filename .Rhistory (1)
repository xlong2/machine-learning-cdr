all_error_sig_info=do.call(rbind,lapply(names(all_loop_sig_frame_list),function(y){
x=all_loop_sig_frame_list[[y]];x$loop=rep(y,dim(x)[1])
# if the first column has the cluster one and the two clusters are not the ssame
H1_related=x[x[,"Var1"]!=x[,"Var2"],]
# most prevalent cluster
each_l=paste(unlist(strsplit(y,"_")[[1]]),collapse="-")
if(each_l=="L3-9"){
most_p="L3-9-cis7-1$"
}else{
most_p=paste(c(each_l,"-1$"),collapse="")
}
H1_cluster_one_recovery_fail=H1_related[grepl(most_p,H1_related$Var1),]
H1_cluster_one_precision_fail=H1_related[grepl(most_p,H1_related$Var2),]
H1_cluster_one_recovery_fail$error_type=rep("1_reco",dim(H1_cluster_one_recovery_fail)[1])
H1_cluster_one_precision_fail$error_type=rep("1_prec",dim(H1_cluster_one_precision_fail)[1])
other_types=H1_related[!(grepl(most_p,H1_related$Var1) |grepl(most_p,H1_related$Var2)),]
other_types$error_type=rep("non_1",dim(other_types)[1])
all_annotated=rbind(rbind(other_types,H1_cluster_one_precision_fail),H1_cluster_one_recovery_fail)
return(all_annotated)
# if the
}))
all_error_sig_info=all_error_sig_info[all_error_sig_info$Var1!=all_error_sig_info$Var2,]
all_error_sig_info$sig_id=rep("insignificant",dim(all_error_sig_info)[1])
all_error_sig_info[all_error_sig_info$significance<=0.025,"sig_id"]=rep("smaller",length(all_error_sig_info[all_error_sig_info$significance<=0.025,"sig_id"]))
all_error_sig_info[all_error_sig_info$significance>=0.975,"sig_id"]=rep("larger",length(all_error_sig_info[all_error_sig_info$significance>=0.975,"sig_id"]))
all_right_sig_info=do.call(rbind,lapply(names(all_loop_sig_frame_list),function(y){
x=all_loop_sig_frame_list[[y]];x$loop=rep(y,dim(x)[1])
# if the first column has the cluster one and the two clusters are not the ssame
H1_related=x[x[,"Var1"]==x[,"Var2"],]
# most prevalent cluster
each_l=paste(unlist(strsplit(y,"_")[[1]]),collapse="-")
if(each_l=="L3-9"){
most_p="L3-9-cis7-1$"
}else{
most_p=paste(c(each_l,"-1$"),collapse="")
}
H1_cluster_one_recovery_fail=H1_related[grepl(most_p,H1_related$Var1),]
H1_cluster_one_recovery_fail$error_type=rep("cluster_1",dim(H1_cluster_one_recovery_fail)[1])
other_types=H1_related[!(grepl(most_p,H1_related$Var1)) ,]
other_types$error_type=rep("non_1",dim(other_types)[1])
all_annotated=rbind(other_types,H1_cluster_one_recovery_fail)
return(all_annotated)
# if the
}))
all_right_sig_info$sig_id=rep("insignificant",dim(all_right_sig_info)[1])
all_right_sig_info[all_right_sig_info$significance<=0.025,"sig_id"]=rep("smaller",length(all_right_sig_info[all_right_sig_info$significance<=0.025,"sig_id"]))
all_right_sig_info[all_right_sig_info$significance>=0.975,"sig_id"]=rep("larger",length(all_right_sig_info[all_right_sig_info$significance>=0.975,"sig_id"]))
effect_size_large=all_error_sig_info[all_error_sig_info$effect_size>=2 &all_error_sig_info$sig_id=="larger",]
effect_size_large=effect_size_large[order(effect_size_large$error_count,decreasing=TRUE),]
effect_size_large_sig=effect_size_large[effect_size_large$error_count>3,]
no_improvement_worse=all_error_sig_info[all_error_sig_info$error_count>3 & all_error_sig_info$sig_id=="larger",]
no_improvement_worse=no_improvement_worse[,c("error_count","mean_simu_error","sd","Var1","Var2","significance")]
names(no_improvement_worse)=c("error_count","mean_simu_error_count","sd","query_cluster","template_cluster","significance")
names(no_improvement_worse)=c("error_count","mean_simu_error_count","sd","query_cluster","template_cluster","significance")
write.csv(not_much_improvement_output,file="./proline_classifier/no_improvement_worse.csv")
not_much_improvement=all_error_sig_info[all_error_sig_info$error_count>3 &(all_error_sig_info$sig_id=="insignificant"),]
not_much_improvement= not_much_improvement[order(not_much_improvement$error_count),]
not_much_improvement_output=not_much_improvement[,c("error_count","mean_simu_error","sd","Var1","Var2","significance")]
names(not_much_improvement_output)=c("error_count","mean_simu_error_count","sd","query_cluster","template_cluster","significance")
write.csv(not_much_improvement_output,file="./proline_classifier/not_much_improvement_output.csv")
improvement_but_still_many_errors=all_error_sig_info[all_error_sig_info$error_count>3 &(all_error_sig_info$sig_id=="smaller"),]
improvement_but_still_many_errors=improvement_but_still_many_errors[,c("error_count","mean_simu_error","sd","Var1","Var2","significance")]
names(improvement_but_still_many_errors)=c("error_count","mean_simu_error_count","sd","query_cluster","template_cluster","significance")
write.csv(improvement_but_still_many_errors,file="./proline_classifier/improvement_but_still_many_errors.csv")
improvement_and_not_very_much_error=all_error_sig_info[all_error_sig_info$error_count<=3 &(all_error_sig_info$sig_id=="smaller"),]
improvement_and_not_very_much_error=improvement_and_not_very_much_error[,c("error_count","mean_simu_error","sd","Var1","Var2","significance")]
names(improvement_and_not_very_much_error)=c("error_count","mean_simu_error_count","sd","query_cluster","template_cluster","significance")
write.csv(improvement_and_not_very_much_error,file="./proline_classifier/improvement_and_not_very_much_error.csv")
improvement_and_not_very_much_error$sig_stat=rep("better than random and little errors",dim(improvement_and_not_very_much_error)[1])
improvement_but_still_many_errors$sig_stat=rep("better than random but still many errors",dim(improvement_but_still_many_errors)[1])
not_much_improvement_output$sig_stat=rep("not different than random",dim(not_much_improvement_output)[1])
no_improvement_worse$sig_stat=rep("worse than random",dim(no_improvement_worse)[1])
all_frames_I_care=rbind(rbind(rbind(improvement_and_not_very_much_error,improvement_but_still_many_errors),not_much_improvement_output),no_improvement_worse)
all_frames_I_care$loop_type=unlist(lapply(strsplit(as.character(all_frames_I_care$query_cluster),"-"),function(x){paste(x[1:2],collapse="-")}))
all_frames_I_care$sig_stat=factor(all_frames_I_care$sig_stat,levels=c("worse than random","not different than random","better than random but still many errors","better than random and little errors"))
col_vec=col_vector[1:length(unique(all_frames_I_care$loop_type))]
# this script is a refactor of the Untitled.R in the R/ directory
# This script is a jazz version of the blind_blast.R in R/directory
# Purpose:
#    Read in a speficic loop type
#    Do LOOCV for blind blast
#    Refer to the rmsd_table to get the rmsd from the template
#    Output the prediction result
#    Do a blast search within the predicted cluster; Or a blast search outside of the clusters or globally if it is not identified as any cluster.
#    Retrieve the rmsd between the predicted sequence and query sequence. Record it
#    Also this script should enable blind blast search as currently employed in the rosetta
#    It should output the data format so that comparison between the prediction accuracy and rmsds are easy
# output:
#   File1:    Confusion table with rownames be the real cases and colnames be the prediction cases of all the predictions curated from LOOCV
#             rmsd_cluster_guided_blast_rmsd_",loop_type,"_",paste(c(each_method,cluster_dis),collapse="-"),"_conftable.rds"
#   File2:    Mean of the three best templated for each sequence and stored as a table  :
#               seq
#                H1_13-1.4312    1.003    1.0023  2.323  3.22
#                ...
#
# Input:
#
#   loop_type : "H2_9"
#   the_method  "blindblast"
#   cluster_dis :   "north"  / "rmsd"
library(Matrix)
library("grid")
library("caret")
#library(RSQLite)
#library("DBI")
library("pryr")
library("protr")
library("gbm")
# generate colors
library(RColorBrewer)
n <- 20
qual_col_pals = brewer.pal.info[brewer.pal.info$category == 'qual',]
col_vector = unlist(mapply(brewer.pal, qual_col_pals$maxcolors, rownames(qual_col_pals)))
col_vector=col_vector[c(1:3,5:(n))]
col_vector=c(col_vector,"#bdbdbd")
pie(rep(1,n), col=col_vector)
test=TRUE
if(test){
the_method="blindblast_just_get_alignment"
cluster_dis="north"
}else{
args <- commandArgs(trailingOnly = TRUE)
loop_type = args[1]
the_method = args[2]
cluster_dis = args[3]
rmsd_table_rdata_dir = "../pairwise_rmsd/rmsd_result/" # post all the L3_9_rmsd_table.Rdata kind of dta
data_by_loop_file_dir ="./Machine_learning_jazz_version/"
load(paste(c(data_by_loop_file_dir,"data_by_loop_type_list_unduplicated.Rdata"),collapse=""))
}
overall_prefix="./proline_classifier/Data_processed"
file=paste(c(overall_prefix,"/data_by_loop_type_list_unduplicated_no_filtering_original.rds"),collapse = "")
data_by_loop_type_list_unduplicated=readRDS(file)
subsitution_matrix_name ="wahtw"  #"/Volumes/lab/macbook/lab_work_data/vall_rmsd/loop_sub_matrix.csv"
subsitution_matrix="PAM30"
result_dir = "./proline_classifier/Data_processed/"
mkcommand=paste(c("mkdir ",result_dir), collapse=" ")
system(mkcommand)
methods= c(the_method) # specify the machine learning methods to be used
each_method=the_method
# end of iterating all folds
the_method="somerandommethod"
data(AAPAM30)
AAPAM30_index=1:20
names(AAPAM30_index)=rownames(AAPAM30)
direct=getwd()
plot_dir="./proline_classifier/Plots/"
save_file1="./proline_classifier/Data_processed/overall_accuracy.rds"
save_file3 = paste(c(result_dir,"all_pred_tables_realcluster_list",".rds"),collapse="")
all_pred_tables_realcluster_list=readRDS(save_file3)
overall_accuracy=readRDS(save_file1)
setwd("./proline_classifier/")
file.sources = list.files(pattern="*functions.R")
sapply(file.sources,source,.GlobalEnv)
setwd(direct)
setwd("./proline_classifier/Data_processed/")
data.sources = list.files(pattern="*.rds")
for(x in data.sources){
x_name=strsplit(x,"\\.")[[1]][1]
assign(x_name,readRDS(x))
}
setwd(direct)
all_error_sig_info=do.call(rbind,lapply(names(all_loop_sig_frame_list),function(y){
x=all_loop_sig_frame_list[[y]];x$loop=rep(y,dim(x)[1])
# if the first column has the cluster one and the two clusters are not the ssame
H1_related=x[x[,"Var1"]!=x[,"Var2"],]
# most prevalent cluster
each_l=paste(unlist(strsplit(y,"_")[[1]]),collapse="-")
if(each_l=="L3-9"){
most_p="L3-9-cis7-1$"
}else{
most_p=paste(c(each_l,"-1$"),collapse="")
}
H1_cluster_one_recovery_fail=H1_related[grepl(most_p,H1_related$Var1),]
H1_cluster_one_precision_fail=H1_related[grepl(most_p,H1_related$Var2),]
H1_cluster_one_recovery_fail$error_type=rep("1_reco",dim(H1_cluster_one_recovery_fail)[1])
H1_cluster_one_precision_fail$error_type=rep("1_prec",dim(H1_cluster_one_precision_fail)[1])
other_types=H1_related[!(grepl(most_p,H1_related$Var1) |grepl(most_p,H1_related$Var2)),]
other_types$error_type=rep("non_1",dim(other_types)[1])
all_annotated=rbind(rbind(other_types,H1_cluster_one_precision_fail),H1_cluster_one_recovery_fail)
return(all_annotated)
# if the
}))
all_error_sig_info=all_error_sig_info[all_error_sig_info$Var1!=all_error_sig_info$Var2,]
all_error_sig_info$sig_id=rep("insignificant",dim(all_error_sig_info)[1])
all_error_sig_info[all_error_sig_info$significance<=0.025,"sig_id"]=rep("smaller",length(all_error_sig_info[all_error_sig_info$significance<=0.025,"sig_id"]))
all_error_sig_info[all_error_sig_info$significance>=0.975,"sig_id"]=rep("larger",length(all_error_sig_info[all_error_sig_info$significance>=0.975,"sig_id"]))
all_right_sig_info=do.call(rbind,lapply(names(all_loop_sig_frame_list),function(y){
x=all_loop_sig_frame_list[[y]];x$loop=rep(y,dim(x)[1])
# if the first column has the cluster one and the two clusters are not the ssame
H1_related=x[x[,"Var1"]==x[,"Var2"],]
# most prevalent cluster
each_l=paste(unlist(strsplit(y,"_")[[1]]),collapse="-")
if(each_l=="L3-9"){
most_p="L3-9-cis7-1$"
}else{
most_p=paste(c(each_l,"-1$"),collapse="")
}
H1_cluster_one_recovery_fail=H1_related[grepl(most_p,H1_related$Var1),]
H1_cluster_one_recovery_fail$error_type=rep("cluster_1",dim(H1_cluster_one_recovery_fail)[1])
other_types=H1_related[!(grepl(most_p,H1_related$Var1)) ,]
other_types$error_type=rep("non_1",dim(other_types)[1])
all_annotated=rbind(other_types,H1_cluster_one_recovery_fail)
return(all_annotated)
# if the
}))
all_right_sig_info$sig_id=rep("insignificant",dim(all_right_sig_info)[1])
all_right_sig_info[all_right_sig_info$significance<=0.025,"sig_id"]=rep("smaller",length(all_right_sig_info[all_right_sig_info$significance<=0.025,"sig_id"]))
all_right_sig_info[all_right_sig_info$significance>=0.975,"sig_id"]=rep("larger",length(all_right_sig_info[all_right_sig_info$significance>=0.975,"sig_id"]))
effect_size_large=all_error_sig_info[all_error_sig_info$effect_size>=2 &all_error_sig_info$sig_id=="larger",]
effect_size_large=effect_size_large[order(effect_size_large$error_count,decreasing=TRUE),]
effect_size_large_sig=effect_size_large[effect_size_large$error_count>3,]
no_improvement_worse=all_error_sig_info[all_error_sig_info$error_count>3 & all_error_sig_info$sig_id=="larger",]
no_improvement_worse=no_improvement_worse[,c("error_count","mean_simu_error","sd","Var1","Var2","significance")]
names(no_improvement_worse)=c("error_count","mean_simu_error_count","sd","query_cluster","template_cluster","significance")
names(no_improvement_worse)=c("error_count","mean_simu_error_count","sd","query_cluster","template_cluster","significance")
write.csv(not_much_improvement_output,file="./proline_classifier/no_improvement_worse.csv")
not_much_improvement=all_error_sig_info[all_error_sig_info$error_count>3 &(all_error_sig_info$sig_id=="insignificant"),]
not_much_improvement= not_much_improvement[order(not_much_improvement$error_count),]
not_much_improvement_output=not_much_improvement[,c("error_count","mean_simu_error","sd","Var1","Var2","significance")]
names(not_much_improvement_output)=c("error_count","mean_simu_error_count","sd","query_cluster","template_cluster","significance")
write.csv(not_much_improvement_output,file="./proline_classifier/not_much_improvement_output.csv")
improvement_but_still_many_errors=all_error_sig_info[all_error_sig_info$error_count>3 &(all_error_sig_info$sig_id=="smaller"),]
improvement_but_still_many_errors=improvement_but_still_many_errors[,c("error_count","mean_simu_error","sd","Var1","Var2","significance")]
names(improvement_but_still_many_errors)=c("error_count","mean_simu_error_count","sd","query_cluster","template_cluster","significance")
write.csv(improvement_but_still_many_errors,file="./proline_classifier/improvement_but_still_many_errors.csv")
improvement_and_not_very_much_error=all_error_sig_info[all_error_sig_info$error_count<=3 &(all_error_sig_info$sig_id=="smaller"),]
improvement_and_not_very_much_error=improvement_and_not_very_much_error[,c("error_count","mean_simu_error","sd","Var1","Var2","significance")]
names(improvement_and_not_very_much_error)=c("error_count","mean_simu_error_count","sd","query_cluster","template_cluster","significance")
write.csv(improvement_and_not_very_much_error,file="./proline_classifier/improvement_and_not_very_much_error.csv")
improvement_and_not_very_much_error$sig_stat=rep("better than random and little errors",dim(improvement_and_not_very_much_error)[1])
improvement_but_still_many_errors$sig_stat=rep("better than random but still many errors",dim(improvement_but_still_many_errors)[1])
not_much_improvement_output$sig_stat=rep("not different than random",dim(not_much_improvement_output)[1])
no_improvement_worse$sig_stat=rep("worse than random",dim(no_improvement_worse)[1])
all_frames_I_care=rbind(rbind(rbind(improvement_and_not_very_much_error,improvement_but_still_many_errors),not_much_improvement_output),no_improvement_worse)
all_frames_I_care$loop_type=unlist(lapply(strsplit(as.character(all_frames_I_care$query_cluster),"-"),function(x){paste(x[1:2],collapse="-")}))
all_frames_I_care$sig_stat=factor(all_frames_I_care$sig_stat,levels=c("worse than random","not different than random","better than random but still many errors","better than random and little errors"))
col_vec=col_vector[1:length(unique(all_frames_I_care$loop_type))]
all_error_sig_info=do.call(rbind,lapply(names(all_loop_sig_frame_list),function(y){
x=all_loop_sig_frame_list[[y]];x$loop=rep(y,dim(x)[1])
# if the first column has the cluster one and the two clusters are not the ssame
H1_related=x[x[,"Var1"]!=x[,"Var2"],]
# most prevalent cluster
each_l=paste(unlist(strsplit(y,"_")[[1]]),collapse="-")
if(each_l=="L3-9"){
most_p="L3-9-cis7-1$"
}else{
most_p=paste(c(each_l,"-1$"),collapse="")
}
H1_cluster_one_recovery_fail=H1_related[grepl(most_p,H1_related$Var1),]
H1_cluster_one_precision_fail=H1_related[grepl(most_p,H1_related$Var2),]
H1_cluster_one_recovery_fail$error_type=rep("1_reco",dim(H1_cluster_one_recovery_fail)[1])
H1_cluster_one_precision_fail$error_type=rep("1_prec",dim(H1_cluster_one_precision_fail)[1])
other_types=H1_related[!(grepl(most_p,H1_related$Var1) |grepl(most_p,H1_related$Var2)),]
other_types$error_type=rep("non_1",dim(other_types)[1])
all_annotated=rbind(rbind(other_types,H1_cluster_one_precision_fail),H1_cluster_one_recovery_fail)
return(all_annotated)
# if the
}))
data.sources
all_significance_simulation
setwd("./proline_classifier/")
file.sources = list.files(pattern="*functions.R")
sapply(file.sources,source,.GlobalEnv)
setwd(direct)
setwd("./proline_classifier/Data_processed/")
# this script is a refactor of the Untitled.R in the R/ directory
# This script is a jazz version of the blind_blast.R in R/directory
# Purpose:
#    Read in a speficic loop type
#    Do LOOCV for blind blast
#    Refer to the rmsd_table to get the rmsd from the template
#    Output the prediction result
#    Do a blast search within the predicted cluster; Or a blast search outside of the clusters or globally if it is not identified as any cluster.
#    Retrieve the rmsd between the predicted sequence and query sequence. Record it
#    Also this script should enable blind blast search as currently employed in the rosetta
#    It should output the data format so that comparison between the prediction accuracy and rmsds are easy
# output:
#   File1:    Confusion table with rownames be the real cases and colnames be the prediction cases of all the predictions curated from LOOCV
#             rmsd_cluster_guided_blast_rmsd_",loop_type,"_",paste(c(each_method,cluster_dis),collapse="-"),"_conftable.rds"
#   File2:    Mean of the three best templated for each sequence and stored as a table  :
#               seq
#                H1_13-1.4312    1.003    1.0023  2.323  3.22
#                ...
#
# Input:
#
#   loop_type : "H2_9"
#   the_method  "blindblast"
#   cluster_dis :   "north"  / "rmsd"
library(Matrix)
library("grid")
library("caret")
#library(RSQLite)
#library("DBI")
library("pryr")
library("protr")
library("gbm")
# generate colors
library(RColorBrewer)
n <- 20
qual_col_pals = brewer.pal.info[brewer.pal.info$category == 'qual',]
col_vector = unlist(mapply(brewer.pal, qual_col_pals$maxcolors, rownames(qual_col_pals)))
col_vector=col_vector[c(1:3,5:(n))]
col_vector=c(col_vector,"#bdbdbd")
pie(rep(1,n), col=col_vector)
test=TRUE
if(test){
the_method="blindblast_just_get_alignment"
cluster_dis="north"
}else{
args <- commandArgs(trailingOnly = TRUE)
loop_type = args[1]
the_method = args[2]
cluster_dis = args[3]
rmsd_table_rdata_dir = "../pairwise_rmsd/rmsd_result/" # post all the L3_9_rmsd_table.Rdata kind of dta
data_by_loop_file_dir ="./Machine_learning_jazz_version/"
load(paste(c(data_by_loop_file_dir,"data_by_loop_type_list_unduplicated.Rdata"),collapse=""))
}
overall_prefix="./proline_classifier/Data_processed"
file=paste(c(overall_prefix,"/data_by_loop_type_list_unduplicated_no_filtering_original.rds"),collapse = "")
data_by_loop_type_list_unduplicated=readRDS(file)
subsitution_matrix_name ="wahtw"  #"/Volumes/lab/macbook/lab_work_data/vall_rmsd/loop_sub_matrix.csv"
subsitution_matrix="PAM30"
result_dir = "./proline_classifier/Data_processed/"
mkcommand=paste(c("mkdir ",result_dir), collapse=" ")
system(mkcommand)
methods= c(the_method) # specify the machine learning methods to be used
each_method=the_method
# end of iterating all folds
the_method="somerandommethod"
data(AAPAM30)
AAPAM30_index=1:20
names(AAPAM30_index)=rownames(AAPAM30)
direct=getwd()
plot_dir="E:/Google_drive/2018 spring/lab_work_data/machine_learning_cdr/proline_classifier/Plots/"
save_file1="./proline_classifier/Data_processed/overall_accuracy.rds"
save_file3 = paste(c(result_dir,"all_pred_tables_realcluster_list",".rds"),collapse="")
all_pred_tables_realcluster_list=readRDS(save_file3)
overall_accuracy=readRDS(save_file1)
setwd("./proline_classifier/")
file.sources = list.files(pattern="*functions.R")
sapply(file.sources,source,.GlobalEnv)
setwd(direct)
setwd("./proline_classifier/Data_processed/")
data.sources = list.files(pattern="*.rds")
for(x in data.sources){
x_name=strsplit(x,"\\.")[[1]][1]
assign(x_name,readRDS(x))
}
setwd(direct)
getwd()
cd ../../
system("cd ../../")
#   File2:    Mean of the three best templated for each sequence and stored as a table  :
#               seq
#                H1_13-1.4312    1.003    1.0023  2.323  3.22
#                ...
#
# Input:
#
#   loop_type : "H2_9"
#   the_method  "blindblast"
#   cluster_dis :   "north"  / "rmsd"
setwd("/Users/xlong/Google Drive/2018_spring/lab_work_data/machine_learning_cdr/")
library(Matrix)
library("grid")
library("caret")
#library(RSQLite)
#library("DBI")
library("pryr")
library("protr")
library("gbm")
# generate colors
library(RColorBrewer)
n <- 20
qual_col_pals = brewer.pal.info[brewer.pal.info$category == 'qual',]
col_vector = unlist(mapply(brewer.pal, qual_col_pals$maxcolors, rownames(qual_col_pals)))
col_vector=col_vector[c(1:3,5:(n))]
col_vector=c(col_vector,"#bdbdbd")
pie(rep(1,n), col=col_vector)
test=TRUE
if(test){
the_method="blindblast_just_get_alignment"
cluster_dis="north"
}else{
args <- commandArgs(trailingOnly = TRUE)
loop_type = args[1]
the_method = args[2]
cluster_dis = args[3]
rmsd_table_rdata_dir = "../pairwise_rmsd/rmsd_result/" # post all the L3_9_rmsd_table.Rdata kind of dta
data_by_loop_file_dir ="./Machine_learning_jazz_version/"
load(paste(c(data_by_loop_file_dir,"data_by_loop_type_list_unduplicated.Rdata"),collapse=""))
}
overall_prefix="./proline_classifier/Data_processed"
file=paste(c(overall_prefix,"/data_by_loop_type_list_unduplicated_no_filtering_original.rds"),collapse = "")
data_by_loop_type_list_unduplicated=readRDS(file)
subsitution_matrix_name ="wahtw"  #"/Volumes/lab/macbook/lab_work_data/vall_rmsd/loop_sub_matrix.csv"
subsitution_matrix="PAM30"
result_dir = "./proline_classifier/Data_processed/"
mkcommand=paste(c("mkdir ",result_dir), collapse=" ")
system(mkcommand)
methods= c(the_method) # specify the machine learning methods to be used
each_method=the_method
# end of iterating all folds
the_method="somerandommethod"
data(AAPAM30)
AAPAM30_index=1:20
names(AAPAM30_index)=rownames(AAPAM30)
direct=getwd()
plot_dir="E:/Google_drive/2018 spring/lab_work_data/machine_learning_cdr/proline_classifier/Plots/"
save_file1="./proline_classifier/Data_processed/overall_accuracy.rds"
save_file3 = paste(c(result_dir,"all_pred_tables_realcluster_list",".rds"),collapse="")
all_pred_tables_realcluster_list=readRDS(save_file3)
overall_accuracy=readRDS(save_file1)
setwd("./proline_classifier/")
file.sources = list.files(pattern="*functions.R")
sapply(file.sources,source,.GlobalEnv)
setwd(direct)
setwd("./proline_classifier/Data_processed/")
data.sources = list.files(pattern="*.rds")
for(x in data.sources){
x_name=strsplit(x,"\\.")[[1]][1]
assign(x_name,readRDS(x))
}
setwd(direct)
